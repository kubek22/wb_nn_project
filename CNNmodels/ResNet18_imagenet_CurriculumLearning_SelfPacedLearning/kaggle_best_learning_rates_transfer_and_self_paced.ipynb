{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-28T17:23:12.956533Z",
     "iopub.status.busy": "2024-05-28T17:23:12.956243Z",
     "iopub.status.idle": "2024-05-28T17:23:12.965808Z",
     "shell.execute_reply": "2024-05-28T17:23:12.964903Z",
     "shell.execute_reply.started": "2024-05-28T17:23:12.956510Z"
    },
    "trusted": true
   },
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "\n",
    "class RSSCN7_DataLoader:\n",
    "    def __init__(self, data_dir, batch_size=32, shuffle=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.dataset = datasets.ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        self.train_dataset, self.test_dataset = self.split_dataset()\n",
    "\n",
    "    def split_dataset(self):\n",
    "        train_size = int(0.8 * len(self.dataset))\n",
    "        test_size = len(self.dataset) - train_size\n",
    "\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "\n",
    "    def get_test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T17:23:15.626189Z",
     "iopub.status.busy": "2024-05-28T17:23:15.625807Z",
     "iopub.status.idle": "2024-05-28T17:23:15.634633Z",
     "shell.execute_reply": "2024-05-28T17:23:15.633753Z",
     "shell.execute_reply.started": "2024-05-28T17:23:15.626160Z"
    },
    "trusted": true
   },
   "source": [
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=47):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False)\n",
    "        self.resnet18.fc = nn.Linear(self.resnet18.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet, self paced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T20:12:37.224132Z",
     "iopub.status.busy": "2024-05-27T20:12:37.223591Z",
     "iopub.status.idle": "2024-05-27T20:51:51.760802Z",
     "shell.execute_reply": "2024-05-27T20:51:51.759768Z",
     "shell.execute_reply.started": "2024-05-27T20:12:37.224093Z"
    },
    "trusted": true
   },
   "source": [
    "from torchvision.models import resnet18\n",
    "# from ..Resnet18.task.model import ResNet18\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train =[]\n",
    "loss_test = []\n",
    "time_epoch = []\n",
    "cur_lambda = []\n",
    "cur_learning_rate = []\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "data_dir = '/kaggle/input/rssnc7/RSSCN7'\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "lambda_beginning = 0.1\n",
    "lambda_end = 1\n",
    "\n",
    "rsscn7_data_loader = RSSCN7_DataLoader(data_dir, batch_size=batch_size, shuffle=True)\n",
    "train_loader = rsscn7_data_loader.get_train_dataloader()\n",
    "test_loader = rsscn7_data_loader.get_test_dataloader()\n",
    "\n",
    "model = resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "num_filters = model.fc.in_features\n",
    "model.fc = nn.Linear(num_filters, 7)\n",
    "\n",
    "######### In case of model pretrained on DTD: uploading the weights #################################################\n",
    "\n",
    "# pretrained_model_path = \"/kaggle/input/resnet18-pretrained-on-dtd/pytorch/version1/1/resnet18_trained_on_DTD_from_80_to_90.pth\"\n",
    "# pretrained_resnet18 = ResNet18()\n",
    "# pretrained_resnet18.load_state_dict(torch.load(pretrained_model_path, map_location=torch.device(device)))\n",
    "\n",
    "# model = pretrained_resnet18.to(device)\n",
    "\n",
    "# model.fc = nn.Linear(47, 7)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opitmizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "my_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "step = 0.05\n",
    "\n",
    "def train_model_self_paced(model, train_loader, test_loader, criterion, optimizer, num_epochs, learning_rate):\n",
    "    device = my_device\n",
    "    model.to(device)\n",
    "    counter = 0\n",
    "\n",
    "    lambda_current = lambda_beginning\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_samples = []\n",
    "\n",
    "        if lambda_current < 1:\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    train_samples.append((inputs, labels, loss.item()))\n",
    "\n",
    "            train_samples.sort(key=lambda x: x[2])  # sort by loss (the first are the easiest)\n",
    "\n",
    "            num_samples_current = int(lambda_current * len(train_samples))\n",
    "\n",
    "            easy_enough_samples = train_samples[:num_samples_current]\n",
    "            easy_enough_inputs = torch.cat([x[0] for x in easy_enough_samples])\n",
    "            easy_enough_labels = torch.cat([x[1] for x in easy_enough_samples])\n",
    "            easy_enough_dataset = TensorDataset(easy_enough_inputs, easy_enough_labels)\n",
    "            easy_enough_loader = DataLoader(easy_enough_dataset, batch_size=batch_size, shuffle=True)\n",
    "        else:\n",
    "            easy_enough_loader = train_loader\n",
    "\n",
    "        for inputs, labels in easy_enough_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_loss / len(easy_enough_loader.dataset)\n",
    "        train_accuracy = correct / total\n",
    "        num_images = len(easy_enough_loader.dataset)\n",
    "\n",
    "        if train_accuracy >= 0.88:\n",
    "            learning_rate = 0.00001\n",
    "        \n",
    "        if train_accuracy >= 0.93:\n",
    "            learning_rate = 0.000001\n",
    "            \n",
    "        if train_accuracy >= 0.96:\n",
    "            learning_rate = 0.0000001\n",
    "\n",
    "        cur_time_ = time.time() - time0\n",
    "\n",
    "        print(\"learing_rate = \", learning_rate)\n",
    "\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Images: {num_images}, Lambda: {lambda_current:.2f}, Time: {cur_time_:.2f} seconds')\n",
    "\n",
    "        if train_accuracy > 0.85:\n",
    "            if lambda_current < 0.6:\n",
    "                lambda_current += step\n",
    "                if lambda_current>1:\n",
    "                    lambda_current = 1\n",
    "            else:\n",
    "                counter = counter + 1\n",
    "                if counter % 2 == 0:\n",
    "                    lambda_current += step\n",
    "                    counter = 0\n",
    "                    if lambda_current>1:\n",
    "                        lambda_current = 1\n",
    "\n",
    "        acc_train.append(train_accuracy)\n",
    "        loss_train.append(train_loss)\n",
    "        time_epoch.append(cur_time_)\n",
    "        cur_lambda.append(lambda_current)\n",
    "        cur_learning_rate.append(learning_rate)\n",
    "\n",
    "        evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "    print('Finished Training Successfully')\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = total_loss / len(test_loader.dataset)\n",
    "    test_accuracy = correct / total\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    acc_test.append(test_accuracy)\n",
    "    loss_test.append(test_loss)\n",
    "\n",
    "\n",
    "train_model_self_paced(model, train_loader, test_loader, criterion, opitmizer, num_epochs, learning_rate)\n",
    "print(\"Accuracy train:\")\n",
    "print(acc_train)\n",
    "print(\"Accuracy test:\")\n",
    "print(acc_test)\n",
    "print(\"Loss train:\")\n",
    "print(loss_train)\n",
    "print(\"Loss test:\")\n",
    "print(loss_test)\n",
    "print(\"Time epoch:\")\n",
    "print(time_epoch)\n",
    "print(\"Learning rate:\")\n",
    "print(cur_learning_rate)\n",
    "print(\"Lambdas:\")\n",
    "print(cur_lambda)\n",
    "\n",
    "torch.save(model, 'resnet18_imagenet_self_paced.pth')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTD, self paced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T16:34:48.042283Z",
     "iopub.status.busy": "2024-05-28T16:34:48.041793Z",
     "iopub.status.idle": "2024-05-28T17:14:03.320768Z",
     "shell.execute_reply": "2024-05-28T17:14:03.319668Z",
     "shell.execute_reply.started": "2024-05-28T16:34:48.042252Z"
    },
    "trusted": true
   },
   "source": [
    "from torchvision.models import resnet18\n",
    "# from ..Resnet18.task.model import ResNet18\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "loss_train =[]\n",
    "loss_test = []\n",
    "time_epoch = []\n",
    "cur_lambda = []\n",
    "cur_learning_rate = []\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "data_dir = '/kaggle/input/rssnc7/RSSCN7'\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "lambda_beginning = 0.1\n",
    "lambda_end = 1\n",
    "\n",
    "rsscn7_data_loader = RSSCN7_DataLoader(data_dir, batch_size=batch_size, shuffle=True)\n",
    "train_loader = rsscn7_data_loader.get_train_dataloader()\n",
    "test_loader = rsscn7_data_loader.get_test_dataloader()\n",
    "\n",
    "my_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "pretrained_model_path = \"/kaggle/input/resnet18-pretrained-on-dtd/pytorch/version1/1/resnet18_trained_on_DTD_from_80_to_90.pth\"\n",
    "pretrained_resnet18 = ResNet18()\n",
    "pretrained_resnet18.load_state_dict(torch.load(pretrained_model_path, map_location=torch.device(my_device)))\n",
    "\n",
    "model = pretrained_resnet18.to(my_device)\n",
    "\n",
    "model.fc = nn.Linear(47, 7)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opitmizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "step = 0.05\n",
    "\n",
    "def train_model_self_paced(model, train_loader, test_loader, criterion, optimizer, num_epochs, learning_rate):\n",
    "    device = my_device\n",
    "    model.to(device)\n",
    "    counter = 0\n",
    "\n",
    "    lambda_current = lambda_beginning\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_samples = []\n",
    "\n",
    "        if lambda_current < 1:\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    train_samples.append((inputs, labels, loss.item()))\n",
    "\n",
    "            train_samples.sort(key=lambda x: x[2])  # sort by loss (the first are the easiest)\n",
    "\n",
    "            num_samples_current = int(lambda_current * len(train_samples))\n",
    "\n",
    "            easy_enough_samples = train_samples[:num_samples_current]\n",
    "            easy_enough_inputs = torch.cat([x[0] for x in easy_enough_samples])\n",
    "            easy_enough_labels = torch.cat([x[1] for x in easy_enough_samples])\n",
    "            easy_enough_dataset = TensorDataset(easy_enough_inputs, easy_enough_labels)\n",
    "            easy_enough_loader = DataLoader(easy_enough_dataset, batch_size=batch_size, shuffle=True)\n",
    "        else:\n",
    "            easy_enough_loader = train_loader\n",
    "\n",
    "        for inputs, labels in easy_enough_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_loss / len(easy_enough_loader.dataset)\n",
    "        train_accuracy = correct / total\n",
    "        num_images = len(easy_enough_loader.dataset)\n",
    "\n",
    "        if train_accuracy >= 0.88:\n",
    "            learning_rate = 0.00001\n",
    "        \n",
    "        if train_accuracy >= 0.93:\n",
    "            learning_rate = 0.000001\n",
    "            \n",
    "        if train_accuracy >= 0.96:\n",
    "            learning_rate = 0.0000001\n",
    "\n",
    "        cur_time_ = time.time() - time0\n",
    "\n",
    "        print(\"learing_rate = \", learning_rate)\n",
    "\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Images: {num_images}, Lambda: {lambda_current:.2f}, Time: {cur_time_:.2f} seconds')\n",
    "\n",
    "        if train_accuracy > 0.8:\n",
    "            if lambda_current < 0.6:\n",
    "                lambda_current += step\n",
    "                if lambda_current>1:\n",
    "                    lambda_current = 1\n",
    "            else:\n",
    "                counter = counter + 1\n",
    "                if counter % 2 == 0:\n",
    "                    lambda_current += step\n",
    "                    counter = 0\n",
    "                    if lambda_current>1:\n",
    "                        lambda_current = 1\n",
    "\n",
    "        acc_train.append(train_accuracy)\n",
    "        loss_train.append(train_loss)\n",
    "        time_epoch.append(cur_time_)\n",
    "        cur_lambda.append(lambda_current)\n",
    "        cur_learning_rate.append(learning_rate)\n",
    "\n",
    "        evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "    print('Finished Training Successfully')\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = total_loss / len(test_loader.dataset)\n",
    "    test_accuracy = correct / total\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    acc_test.append(test_accuracy)\n",
    "    loss_test.append(test_loss)\n",
    "\n",
    "\n",
    "train_model_self_paced(model, train_loader, test_loader, criterion, opitmizer, num_epochs, learning_rate)\n",
    "print(\"Accuracy train:\")\n",
    "print(acc_train)\n",
    "print(\"Accuracy test:\")\n",
    "print(acc_test)\n",
    "print(\"Loss train:\")\n",
    "print(loss_train)\n",
    "print(\"Loss test:\")\n",
    "print(loss_test)\n",
    "print(\"Time epoch:\")\n",
    "print(time_epoch)\n",
    "print(\"Learning rate:\")\n",
    "print(cur_learning_rate)\n",
    "print(\"Lambdas:\")\n",
    "print(cur_lambda)\n",
    "\n",
    "torch.save(model, 'resnet18_DTD_self_paced.pth')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer_learning_imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:11:01.365617Z",
     "iopub.status.busy": "2024-05-28T10:11:01.365253Z",
     "iopub.status.idle": "2024-05-28T10:43:14.681966Z",
     "shell.execute_reply": "2024-05-28T10:43:14.681002Z",
     "shell.execute_reply.started": "2024-05-28T10:11:01.365587Z"
    },
    "trusted": true
   },
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "epoch_time = []\n",
    "learning_rates = []\n",
    "\n",
    "class RCCN7DataLoader:\n",
    "    def __init__(self, data_dir, batch_size=32, shuffle=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.dataset = datasets.ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        self.train_dataset, self.test_dataset = self.split_dataset()\n",
    "\n",
    "    def split_dataset(self):\n",
    "        train_size = int(0.8 * len(self.dataset))\n",
    "        test_size = len(self.dataset) - train_size\n",
    "\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "\n",
    "    def get_test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "data_dir = '/kaggle/input/rssnc7/RSSCN7'\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "data_loader = RCCN7DataLoader(data_dir=data_dir, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "resnet18 = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "\n",
    "\n",
    "for name, param in resnet18.named_parameters():\n",
    "    if 'fc' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
    "\n",
    "device = \"cuda\"\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=learning_rate)\n",
    "\n",
    "#most optimal\n",
    "epochs = 100\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs, learning_rate):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "        if epoch_accuracy >= 85:\n",
    "            learning_rate = 0.0005\n",
    "\n",
    "        if epoch_accuracy >= 89:\n",
    "            learning_rate = 0.00005\n",
    "\n",
    "        if epoch_accuracy >= 92:\n",
    "            learning_rate = 0.000001\n",
    "\n",
    "        time_cur = time.time() - time0\n",
    "        print(\"learing_rate = \", learning_rate)\n",
    "\n",
    "        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "        test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "        print(f'Testing - Epoch {epoch+1}/{num_epochs}, Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n",
    "        print(f'Time: {time_cur:.2f} seconds')\n",
    "\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        test_acc.append(test_accuracy)\n",
    "        loss_train.append(epoch_loss)\n",
    "        loss_test.append(test_loss)\n",
    "        learning_rates.append(learning_rate)\n",
    "        epoch_time.append(time_cur)\n",
    "\n",
    "    print('Training complete.')\n",
    "\n",
    "def evaluate_model(model, criterion, test_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / total_samples\n",
    "    test_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "train_loader = data_loader.get_train_dataloader()\n",
    "test_loader = data_loader.get_test_dataloader()\n",
    "\n",
    "train_model(resnet18, criterion, optimizer, train_loader, test_loader, epochs, learning_rate)\n",
    "\n",
    "print('Training completed successfully.')\n",
    "print(\"Training accuracy:\")\n",
    "print(train_acc)\n",
    "print(\"Test accuracy:\")\n",
    "print(test_acc)\n",
    "print('Loss train:')\n",
    "print(loss_train)\n",
    "print(\"Test loss:\")\n",
    "print(loss_test)\n",
    "print(\"Learning rate:\")\n",
    "print(learning_rates)\n",
    "print(\"Epoch times:\")\n",
    "print(epoch_time)\n",
    "\n",
    "torch.save(resnet18, 'resnet18_imagenet_transfer_learning.pth')"
   ],
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Transfer Learning DTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:25:27.621744Z",
     "iopub.status.busy": "2024-05-28T09:25:27.621400Z",
     "iopub.status.idle": "2024-05-28T09:57:30.491728Z",
     "shell.execute_reply": "2024-05-28T09:57:30.490373Z",
     "shell.execute_reply.started": "2024-05-28T09:25:27.621718Z"
    },
    "trusted": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "\n",
    "class RSSCN7_DataLoader:\n",
    "    def __init__(self, data_dir, batch_size=32, shuffle=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.dataset = datasets.ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        self.train_dataset, self.test_dataset = self.split_dataset()\n",
    "\n",
    "    def split_dataset(self):\n",
    "        train_size = int(0.8 * len(self.dataset))\n",
    "        test_size = len(self.dataset) - train_size\n",
    "\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "\n",
    "    def get_test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "time0 = time.time()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(10)\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "epoch_time = []\n",
    "learning_rates = []\n",
    "\n",
    "data_dir = '/kaggle/input/rssnc7/RSSCN7'\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "data_loader = RSSCN7_DataLoader(data_dir=data_dir, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "pretrained_model_path = '/kaggle/input/resnet18-pretrained-on-dtd/pytorch/version1/1/resnet18_trained_on_DTD_from_80_to_90.pth'\n",
    "pretrained_resnet18 = ResNet18()\n",
    "pretrained_resnet18.load_state_dict(torch.load(pretrained_model_path, map_location=device))\n",
    "\n",
    "pretrained_resnet18.fc = nn.Linear(pretrained_resnet18.resnet18.fc.in_features, 7)\n",
    "\n",
    "pretrained_resnet18 = pretrained_resnet18.to(device)\n",
    "\n",
    "for name, param in pretrained_resnet18.named_parameters():\n",
    "    if 'fc' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pretrained_resnet18.parameters(), lr=learning_rate)\n",
    "\n",
    "# most optimal\n",
    "epochs = 100\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs, learning_rate):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_accuracy = correct_predictions / total_samples \n",
    "\n",
    "        if epoch_accuracy >= 0.85:\n",
    "            learning_rate = 0.0001\n",
    "\n",
    "\n",
    "        time_cur = time.time() - time0\n",
    "        print(\"learning_rate = \", learning_rate)\n",
    "\n",
    "        print(f'Training - Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "        test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "        print(f'Testing - Epoch {epoch + 1}/{num_epochs}, Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n",
    "        print(f'Time: {time_cur:.2f} seconds')\n",
    "\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        test_acc.append(test_accuracy)\n",
    "        loss_train.append(epoch_loss)\n",
    "        loss_test.append(test_loss)\n",
    "        learning_rates.append(learning_rate)\n",
    "        epoch_time.append(time_cur)\n",
    "\n",
    "    print('Training complete.')\n",
    "\n",
    "def evaluate_model(model, criterion, test_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / total_samples\n",
    "    test_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "train_loader = data_loader.get_train_dataloader()\n",
    "test_loader = data_loader.get_test_dataloader()\n",
    "\n",
    "train_model(pretrained_resnet18, criterion, optimizer, train_loader, test_loader, epochs, learning_rate)\n",
    "\n",
    "print('Training completed successfully.')\n",
    "print(\"Training accuracy:\")\n",
    "print(train_acc)\n",
    "print(\"Test accuracy:\")\n",
    "print(test_acc)\n",
    "print('Loss train:')\n",
    "print(loss_train)\n",
    "print(\"Test loss:\")\n",
    "print(loss_test)\n",
    "print(\"Learning rate:\")\n",
    "print(learning_rates)\n",
    "print(\"Epoch times:\")\n",
    "print(epoch_time)\n",
    "\n",
    "torch.save(pretrained_resnet18, 'resnet18_DTD_transfer_learning.pth')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5044311,
     "sourceId": 8461855,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 45451,
     "sourceId": 54224,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
