# final

learning_rate =  0.001
Training - Epoch 1/100, Loss: 4.0110, Accuracy: 0.2576
Testing - Epoch 1/100, Loss: 2.7163, Accuracy: 0.3161
Time: 29.39 seconds
learning_rate =  0.001
Training - Epoch 2/100, Loss: 1.8973, Accuracy: 0.4647
Testing - Epoch 2/100, Loss: 1.4172, Accuracy: 0.5214
Time: 51.02 seconds
learning_rate =  0.001
Training - Epoch 3/100, Loss: 1.2247, Accuracy: 0.6045
Testing - Epoch 3/100, Loss: 1.0610, Accuracy: 0.6411
Time: 70.00 seconds
learning_rate =  0.001
Training - Epoch 4/100, Loss: 0.9689, Accuracy: 0.6741
Testing - Epoch 4/100, Loss: 0.8938, Accuracy: 0.6964
Time: 89.01 seconds
learning_rate =  0.001
Training - Epoch 5/100, Loss: 0.8448, Accuracy: 0.7058
Testing - Epoch 5/100, Loss: 0.7807, Accuracy: 0.7304
Time: 107.73 seconds
learning_rate =  0.001
Training - Epoch 6/100, Loss: 0.7634, Accuracy: 0.7210
Testing - Epoch 6/100, Loss: 0.7291, Accuracy: 0.7321
Time: 126.31 seconds
learning_rate =  0.001
Training - Epoch 7/100, Loss: 0.7233, Accuracy: 0.7366
Testing - Epoch 7/100, Loss: 0.6633, Accuracy: 0.7446
Time: 145.27 seconds
learning_rate =  0.001
Training - Epoch 8/100, Loss: 0.6641, Accuracy: 0.7576
Testing - Epoch 8/100, Loss: 0.6462, Accuracy: 0.7643
Time: 164.15 seconds
learning_rate =  0.001
Training - Epoch 9/100, Loss: 0.6212, Accuracy: 0.7594
Testing - Epoch 9/100, Loss: 0.5912, Accuracy: 0.7875
Time: 182.87 seconds
learning_rate =  0.001
Training - Epoch 10/100, Loss: 0.5998, Accuracy: 0.7750
Testing - Epoch 10/100, Loss: 0.6027, Accuracy: 0.7804
Time: 202.22 seconds
learning_rate =  0.001
Training - Epoch 11/100, Loss: 0.5547, Accuracy: 0.7969
Testing - Epoch 11/100, Loss: 0.5687, Accuracy: 0.7857
Time: 220.85 seconds
learning_rate =  0.001
Training - Epoch 12/100, Loss: 0.5679, Accuracy: 0.8022
Testing - Epoch 12/100, Loss: 0.5733, Accuracy: 0.7839
Time: 239.69 seconds
learning_rate =  0.001
Training - Epoch 13/100, Loss: 0.5544, Accuracy: 0.7960
Testing - Epoch 13/100, Loss: 0.5493, Accuracy: 0.7893
Time: 258.71 seconds
learning_rate =  0.001
Training - Epoch 14/100, Loss: 0.5445, Accuracy: 0.8080
Testing - Epoch 14/100, Loss: 0.5357, Accuracy: 0.7946
Time: 277.85 seconds
learning_rate =  0.001
Training - Epoch 15/100, Loss: 0.5392, Accuracy: 0.8000
Testing - Epoch 15/100, Loss: 0.5180, Accuracy: 0.8161
Time: 296.53 seconds
learning_rate =  0.001
Training - Epoch 16/100, Loss: 0.5173, Accuracy: 0.8076
Testing - Epoch 16/100, Loss: 0.5502, Accuracy: 0.8036
Time: 315.36 seconds
learning_rate =  0.001
Training - Epoch 17/100, Loss: 0.5001, Accuracy: 0.8214
Testing - Epoch 17/100, Loss: 0.5440, Accuracy: 0.7964
Time: 334.30 seconds
learning_rate =  0.001
Training - Epoch 18/100, Loss: 0.4877, Accuracy: 0.8254
Testing - Epoch 18/100, Loss: 0.5084, Accuracy: 0.8089
Time: 353.10 seconds
learning_rate =  0.001
Training - Epoch 19/100, Loss: 0.4919, Accuracy: 0.8129
Testing - Epoch 19/100, Loss: 0.5094, Accuracy: 0.8071
Time: 372.12 seconds
learning_rate =  0.001
Training - Epoch 20/100, Loss: 0.4786, Accuracy: 0.8192
Testing - Epoch 20/100, Loss: 0.4875, Accuracy: 0.8286
Time: 391.26 seconds
learning_rate =  0.001
Training - Epoch 21/100, Loss: 0.4687, Accuracy: 0.8241
Testing - Epoch 21/100, Loss: 0.4834, Accuracy: 0.8232
Time: 409.96 seconds
learning_rate =  0.001
Training - Epoch 22/100, Loss: 0.4660, Accuracy: 0.8272
Testing - Epoch 22/100, Loss: 0.4817, Accuracy: 0.8250
Time: 428.90 seconds
learning_rate =  0.001
Training - Epoch 23/100, Loss: 0.4488, Accuracy: 0.8335
Testing - Epoch 23/100, Loss: 0.4793, Accuracy: 0.8304
Time: 447.96 seconds
learning_rate =  0.001
Training - Epoch 24/100, Loss: 0.4317, Accuracy: 0.8442
Testing - Epoch 24/100, Loss: 0.4944, Accuracy: 0.8250
Time: 466.70 seconds
learning_rate =  0.001
Training - Epoch 25/100, Loss: 0.4406, Accuracy: 0.8268
Testing - Epoch 25/100, Loss: 0.4970, Accuracy: 0.8339
Time: 485.41 seconds
learning_rate =  0.001
Training - Epoch 26/100, Loss: 0.4458, Accuracy: 0.8321
Testing - Epoch 26/100, Loss: 0.4509, Accuracy: 0.8357
Time: 504.27 seconds
learning_rate =  0.001
Training - Epoch 27/100, Loss: 0.4302, Accuracy: 0.8433
Testing - Epoch 27/100, Loss: 0.4656, Accuracy: 0.8286
Time: 523.00 seconds
learning_rate =  0.001
Training - Epoch 28/100, Loss: 0.4343, Accuracy: 0.8429
Testing - Epoch 28/100, Loss: 0.4612, Accuracy: 0.8357
Time: 541.75 seconds
learning_rate =  0.001
Training - Epoch 29/100, Loss: 0.4260, Accuracy: 0.8388
Testing - Epoch 29/100, Loss: 0.4772, Accuracy: 0.8286
Time: 560.73 seconds
learning_rate =  0.001
Training - Epoch 30/100, Loss: 0.4304, Accuracy: 0.8424
Testing - Epoch 30/100, Loss: 0.4435, Accuracy: 0.8375
Time: 579.47 seconds
learning_rate =  0.001
Training - Epoch 31/100, Loss: 0.4040, Accuracy: 0.8491
Testing - Epoch 31/100, Loss: 0.4678, Accuracy: 0.8250
Time: 598.01 seconds
learning_rate =  0.0001
Training - Epoch 32/100, Loss: 0.3972, Accuracy: 0.8585
Testing - Epoch 32/100, Loss: 0.4507, Accuracy: 0.8321
Time: 617.14 seconds
learning_rate =  0.0001
Training - Epoch 33/100, Loss: 0.4038, Accuracy: 0.8571
Testing - Epoch 33/100, Loss: 0.4562, Accuracy: 0.8321
Time: 636.50 seconds
learning_rate =  0.0001
Training - Epoch 34/100, Loss: 0.4037, Accuracy: 0.8518
Testing - Epoch 34/100, Loss: 0.4429, Accuracy: 0.8393
Time: 655.40 seconds
learning_rate =  0.0001
Training - Epoch 35/100, Loss: 0.4031, Accuracy: 0.8536
Testing - Epoch 35/100, Loss: 0.4427, Accuracy: 0.8339
Time: 674.44 seconds
learning_rate =  0.0001
Training - Epoch 36/100, Loss: 0.3970, Accuracy: 0.8509
Testing - Epoch 36/100, Loss: 0.4451, Accuracy: 0.8375
Time: 693.15 seconds
learning_rate =  0.0001
Training - Epoch 37/100, Loss: 0.3781, Accuracy: 0.8580
Testing - Epoch 37/100, Loss: 0.4864, Accuracy: 0.8357
Time: 712.04 seconds
learning_rate =  0.0001
Training - Epoch 38/100, Loss: 0.4116, Accuracy: 0.8509
Testing - Epoch 38/100, Loss: 0.4606, Accuracy: 0.8304
Time: 731.26 seconds
learning_rate =  0.0001
Training - Epoch 39/100, Loss: 0.3924, Accuracy: 0.8571
Testing - Epoch 39/100, Loss: 0.4258, Accuracy: 0.8464
Time: 750.01 seconds
learning_rate =  0.0001
Training - Epoch 40/100, Loss: 0.3759, Accuracy: 0.8683
Testing - Epoch 40/100, Loss: 0.4371, Accuracy: 0.8339
Time: 768.72 seconds
learning_rate =  0.0001
Training - Epoch 41/100, Loss: 0.3797, Accuracy: 0.8612
Testing - Epoch 41/100, Loss: 0.4333, Accuracy: 0.8393
Time: 787.30 seconds
learning_rate =  0.0001
Training - Epoch 42/100, Loss: 0.3591, Accuracy: 0.8679
Testing - Epoch 42/100, Loss: 0.4276, Accuracy: 0.8446
Time: 806.27 seconds
learning_rate =  0.0001
Training - Epoch 43/100, Loss: 0.3779, Accuracy: 0.8616
Testing - Epoch 43/100, Loss: 0.4560, Accuracy: 0.8411
Time: 825.11 seconds
learning_rate =  0.0001
Training - Epoch 44/100, Loss: 0.3728, Accuracy: 0.8643
Testing - Epoch 44/100, Loss: 0.4164, Accuracy: 0.8571
Time: 843.66 seconds
learning_rate =  0.0001
Training - Epoch 45/100, Loss: 0.3800, Accuracy: 0.8522
Testing - Epoch 45/100, Loss: 0.4351, Accuracy: 0.8304
Time: 862.90 seconds
learning_rate =  0.0001
Training - Epoch 46/100, Loss: 0.3645, Accuracy: 0.8638
Testing - Epoch 46/100, Loss: 0.4237, Accuracy: 0.8607
Time: 881.77 seconds
learning_rate =  0.0001
Training - Epoch 47/100, Loss: 0.3547, Accuracy: 0.8696
Testing - Epoch 47/100, Loss: 0.4340, Accuracy: 0.8339
Time: 900.60 seconds
learning_rate =  0.0001
Training - Epoch 48/100, Loss: 0.3683, Accuracy: 0.8621
Testing - Epoch 48/100, Loss: 0.4261, Accuracy: 0.8446
Time: 919.48 seconds
learning_rate =  0.0001
Training - Epoch 49/100, Loss: 0.3709, Accuracy: 0.8634
Testing - Epoch 49/100, Loss: 0.4142, Accuracy: 0.8446
Time: 938.88 seconds
learning_rate =  0.0001
Training - Epoch 50/100, Loss: 0.3381, Accuracy: 0.8902
Testing - Epoch 50/100, Loss: 0.4496, Accuracy: 0.8339
Time: 957.92 seconds
learning_rate =  0.0001
Training - Epoch 51/100, Loss: 0.3429, Accuracy: 0.8737
Testing - Epoch 51/100, Loss: 0.4171, Accuracy: 0.8411
Time: 977.33 seconds
learning_rate =  0.0001
Training - Epoch 52/100, Loss: 0.3747, Accuracy: 0.8576
Testing - Epoch 52/100, Loss: 0.4126, Accuracy: 0.8518
Time: 996.78 seconds
learning_rate =  0.0001
Training - Epoch 53/100, Loss: 0.3441, Accuracy: 0.8696
Testing - Epoch 53/100, Loss: 0.4415, Accuracy: 0.8357
Time: 1016.05 seconds
learning_rate =  0.0001
Training - Epoch 54/100, Loss: 0.3319, Accuracy: 0.8839
Testing - Epoch 54/100, Loss: 0.4250, Accuracy: 0.8536
Time: 1035.09 seconds
learning_rate =  0.0001
Training - Epoch 55/100, Loss: 0.3548, Accuracy: 0.8656
Testing - Epoch 55/100, Loss: 0.4412, Accuracy: 0.8411
Time: 1054.55 seconds
learning_rate =  0.0001
Training - Epoch 56/100, Loss: 0.3370, Accuracy: 0.8799
Testing - Epoch 56/100, Loss: 0.4241, Accuracy: 0.8518
Time: 1073.77 seconds
learning_rate =  0.0001
Training - Epoch 57/100, Loss: 0.3329, Accuracy: 0.8844
Testing - Epoch 57/100, Loss: 0.4132, Accuracy: 0.8500
Time: 1093.38 seconds
learning_rate =  0.0001
Training - Epoch 58/100, Loss: 0.3303, Accuracy: 0.8799
Testing - Epoch 58/100, Loss: 0.4226, Accuracy: 0.8500
Time: 1113.00 seconds
learning_rate =  0.0001
Training - Epoch 59/100, Loss: 0.3260, Accuracy: 0.8826
Testing - Epoch 59/100, Loss: 0.4323, Accuracy: 0.8357
Time: 1131.84 seconds
learning_rate =  0.0001
Training - Epoch 60/100, Loss: 0.3381, Accuracy: 0.8750
Testing - Epoch 60/100, Loss: 0.4077, Accuracy: 0.8482
Time: 1150.88 seconds
learning_rate =  0.0001
Training - Epoch 61/100, Loss: 0.3281, Accuracy: 0.8848
Testing - Epoch 61/100, Loss: 0.4225, Accuracy: 0.8464
Time: 1170.18 seconds
learning_rate =  0.0001
Training - Epoch 62/100, Loss: 0.3548, Accuracy: 0.8821
Testing - Epoch 62/100, Loss: 0.4022, Accuracy: 0.8536
Time: 1189.24 seconds
learning_rate =  0.0001
Training - Epoch 63/100, Loss: 0.3227, Accuracy: 0.8817
Testing - Epoch 63/100, Loss: 0.4341, Accuracy: 0.8446
Time: 1208.08 seconds
learning_rate =  0.0001
Training - Epoch 64/100, Loss: 0.3257, Accuracy: 0.8844
Testing - Epoch 64/100, Loss: 0.4166, Accuracy: 0.8482
Time: 1227.38 seconds
learning_rate =  0.0001
Training - Epoch 65/100, Loss: 0.3261, Accuracy: 0.8879
Testing - Epoch 65/100, Loss: 0.4021, Accuracy: 0.8536
Time: 1246.61 seconds
learning_rate =  0.0001
Training - Epoch 66/100, Loss: 0.3236, Accuracy: 0.8817
Testing - Epoch 66/100, Loss: 0.3972, Accuracy: 0.8500
Time: 1266.56 seconds
learning_rate =  0.0001
Training - Epoch 67/100, Loss: 0.3319, Accuracy: 0.8763
Testing - Epoch 67/100, Loss: 0.4150, Accuracy: 0.8536
Time: 1286.40 seconds
learning_rate =  0.0001
Training - Epoch 68/100, Loss: 0.3073, Accuracy: 0.8884
Testing - Epoch 68/100, Loss: 0.3966, Accuracy: 0.8571
Time: 1305.23 seconds
learning_rate =  0.0001
Training - Epoch 69/100, Loss: 0.3123, Accuracy: 0.8871
Testing - Epoch 69/100, Loss: 0.4087, Accuracy: 0.8500
Time: 1324.01 seconds
learning_rate =  0.0001
Training - Epoch 70/100, Loss: 0.3345, Accuracy: 0.8795
Testing - Epoch 70/100, Loss: 0.4116, Accuracy: 0.8518
Time: 1343.49 seconds
learning_rate =  0.0001
Training - Epoch 71/100, Loss: 0.3468, Accuracy: 0.8732
Testing - Epoch 71/100, Loss: 0.4189, Accuracy: 0.8446
Time: 1362.20 seconds
learning_rate =  0.0001
Training - Epoch 72/100, Loss: 0.3183, Accuracy: 0.8804
Testing - Epoch 72/100, Loss: 0.4283, Accuracy: 0.8500
Time: 1381.45 seconds
learning_rate =  0.0001
Training - Epoch 73/100, Loss: 0.3020, Accuracy: 0.8884
Testing - Epoch 73/100, Loss: 0.4259, Accuracy: 0.8446
Time: 1400.71 seconds
learning_rate =  0.0001
Training - Epoch 74/100, Loss: 0.3174, Accuracy: 0.8879
Testing - Epoch 74/100, Loss: 0.4250, Accuracy: 0.8357
Time: 1419.55 seconds
learning_rate =  0.0001
Training - Epoch 75/100, Loss: 0.3116, Accuracy: 0.8790
Testing - Epoch 75/100, Loss: 0.4284, Accuracy: 0.8518
Time: 1438.66 seconds
learning_rate =  0.0001
Training - Epoch 76/100, Loss: 0.3203, Accuracy: 0.8821
Testing - Epoch 76/100, Loss: 0.4057, Accuracy: 0.8554
Time: 1458.47 seconds
learning_rate =  0.0001
Training - Epoch 77/100, Loss: 0.3050, Accuracy: 0.8893
Testing - Epoch 77/100, Loss: 0.4668, Accuracy: 0.8268
Time: 1477.90 seconds
learning_rate =  0.0001
Training - Epoch 78/100, Loss: 0.3146, Accuracy: 0.8879
Testing - Epoch 78/100, Loss: 0.3910, Accuracy: 0.8589
Time: 1497.40 seconds
learning_rate =  0.0001
Training - Epoch 79/100, Loss: 0.3080, Accuracy: 0.8924
Testing - Epoch 79/100, Loss: 0.3987, Accuracy: 0.8518
Time: 1516.95 seconds
learning_rate =  0.0001
Training - Epoch 80/100, Loss: 0.3095, Accuracy: 0.8929
Testing - Epoch 80/100, Loss: 0.4356, Accuracy: 0.8357
Time: 1536.35 seconds
learning_rate =  0.0001
Training - Epoch 81/100, Loss: 0.2946, Accuracy: 0.9009
Testing - Epoch 81/100, Loss: 0.4265, Accuracy: 0.8429
Time: 1555.48 seconds
learning_rate =  0.0001
Training - Epoch 82/100, Loss: 0.2926, Accuracy: 0.8924
Testing - Epoch 82/100, Loss: 0.3865, Accuracy: 0.8607
Time: 1575.50 seconds
learning_rate =  0.0001
Training - Epoch 83/100, Loss: 0.2778, Accuracy: 0.9062
Testing - Epoch 83/100, Loss: 0.3860, Accuracy: 0.8571
Time: 1594.74 seconds
learning_rate =  0.0001
Training - Epoch 84/100, Loss: 0.3004, Accuracy: 0.8884
Testing - Epoch 84/100, Loss: 0.4302, Accuracy: 0.8429
Time: 1613.45 seconds
learning_rate =  0.0001
Training - Epoch 85/100, Loss: 0.3060, Accuracy: 0.8893
Testing - Epoch 85/100, Loss: 0.3945, Accuracy: 0.8625
Time: 1632.75 seconds
learning_rate =  0.0001
Training - Epoch 86/100, Loss: 0.2967, Accuracy: 0.8911
Testing - Epoch 86/100, Loss: 0.3876, Accuracy: 0.8589
Time: 1652.17 seconds
learning_rate =  0.0001
Training - Epoch 87/100, Loss: 0.2977, Accuracy: 0.8915
Testing - Epoch 87/100, Loss: 0.4049, Accuracy: 0.8571
Time: 1671.02 seconds
learning_rate =  0.0001
Training - Epoch 88/100, Loss: 0.2762, Accuracy: 0.9027
Testing - Epoch 88/100, Loss: 0.4465, Accuracy: 0.8339
Time: 1690.01 seconds
learning_rate =  0.0001
Training - Epoch 89/100, Loss: 0.3007, Accuracy: 0.8879
Testing - Epoch 89/100, Loss: 0.3921, Accuracy: 0.8625
Time: 1709.30 seconds
learning_rate =  0.0001
Training - Epoch 90/100, Loss: 0.2979, Accuracy: 0.8964
Testing - Epoch 90/100, Loss: 0.4161, Accuracy: 0.8518
Time: 1728.38 seconds
learning_rate =  0.0001
Training - Epoch 91/100, Loss: 0.2821, Accuracy: 0.8964
Testing - Epoch 91/100, Loss: 0.3864, Accuracy: 0.8643
Time: 1747.21 seconds
learning_rate =  0.0001
Training - Epoch 92/100, Loss: 0.2859, Accuracy: 0.8973
Testing - Epoch 92/100, Loss: 0.4142, Accuracy: 0.8500
Time: 1766.08 seconds
learning_rate =  0.0001
Training - Epoch 93/100, Loss: 0.3051, Accuracy: 0.8879
Testing - Epoch 93/100, Loss: 0.3908, Accuracy: 0.8625
Time: 1784.83 seconds
learning_rate =  0.0001
Training - Epoch 94/100, Loss: 0.3027, Accuracy: 0.8893
Testing - Epoch 94/100, Loss: 0.4013, Accuracy: 0.8607
Time: 1803.69 seconds
learning_rate =  0.0001
Training - Epoch 95/100, Loss: 0.2919, Accuracy: 0.8924
Testing - Epoch 95/100, Loss: 0.3987, Accuracy: 0.8571
Time: 1823.62 seconds
learning_rate =  0.0001
Training - Epoch 96/100, Loss: 0.3002, Accuracy: 0.8875
Testing - Epoch 96/100, Loss: 0.4256, Accuracy: 0.8357
Time: 1843.20 seconds
learning_rate =  0.0001
Training - Epoch 97/100, Loss: 0.2995, Accuracy: 0.8902
Testing - Epoch 97/100, Loss: 0.3976, Accuracy: 0.8500
Time: 1861.94 seconds
learning_rate =  0.0001
Training - Epoch 98/100, Loss: 0.2907, Accuracy: 0.8955
Testing - Epoch 98/100, Loss: 0.4093, Accuracy: 0.8589
Time: 1881.22 seconds
learning_rate =  0.0001
Training - Epoch 99/100, Loss: 0.2877, Accuracy: 0.8942
Testing - Epoch 99/100, Loss: 0.4309, Accuracy: 0.8500
Time: 1899.87 seconds
learning_rate =  0.0001
Training - Epoch 100/100, Loss: 0.2919, Accuracy: 0.8982
Testing - Epoch 100/100, Loss: 0.3953, Accuracy: 0.8571
Time: 1918.96 seconds
Training complete.
Training completed successfully.
Training accuracy:
[0.2575892857142857, 0.46473214285714287, 0.6044642857142857, 0.6741071428571429, 0.7058035714285714, 0.7209821428571429, 0.7366071428571429, 0.7575892857142857, 0.759375, 0.775, 0.796875, 0.8022321428571428, 0.7959821428571429, 0.8080357142857143, 0.8, 0.8075892857142857, 0.8214285714285714, 0.8254464285714286, 0.8129464285714286, 0.8191964285714286, 0.8241071428571428, 0.8272321428571429, 0.8334821428571428, 0.8441964285714286, 0.8267857142857142, 0.8321428571428572, 0.8433035714285714, 0.8428571428571429, 0.8388392857142857, 0.8424107142857142, 0.8491071428571428, 0.8584821428571429, 0.8571428571428571, 0.8517857142857143, 0.8535714285714285, 0.8508928571428571, 0.8580357142857142, 0.8508928571428571, 0.8571428571428571, 0.8683035714285714, 0.8611607142857143, 0.8678571428571429, 0.8616071428571429, 0.8642857142857143, 0.8522321428571429, 0.8638392857142857, 0.8696428571428572, 0.8620535714285714, 0.8633928571428572, 0.8901785714285714, 0.8736607142857142, 0.8575892857142857, 0.8696428571428572, 0.8839285714285714, 0.865625, 0.8799107142857143, 0.884375, 0.8799107142857143, 0.8825892857142857, 0.875, 0.8848214285714285, 0.8821428571428571, 0.8816964285714286, 0.884375, 0.8879464285714286, 0.8816964285714286, 0.8763392857142858, 0.8883928571428571, 0.8870535714285714, 0.8794642857142857, 0.8732142857142857, 0.8803571428571428, 0.8883928571428571, 0.8879464285714286, 0.8790178571428572, 0.8821428571428571, 0.8892857142857142, 0.8879464285714286, 0.8924107142857143, 0.8928571428571429, 0.9008928571428572, 0.8924107142857143, 0.90625, 0.8883928571428571, 0.8892857142857142, 0.8910714285714286, 0.8915178571428571, 0.9026785714285714, 0.8879464285714286, 0.8964285714285715, 0.8964285714285715, 0.8973214285714286, 0.8879464285714286, 0.8892857142857142, 0.8924107142857143, 0.8875, 0.8901785714285714, 0.8955357142857143, 0.8941964285714286, 0.8982142857142857]
Test accuracy:
[0.31607142857142856, 0.5214285714285715, 0.6410714285714286, 0.6964285714285714, 0.7303571428571428, 0.7321428571428571, 0.7446428571428572, 0.7642857142857142, 0.7875, 0.7803571428571429, 0.7857142857142857, 0.7839285714285714, 0.7892857142857143, 0.7946428571428571, 0.8160714285714286, 0.8035714285714286, 0.7964285714285714, 0.8089285714285714, 0.8071428571428572, 0.8285714285714286, 0.8232142857142857, 0.825, 0.8303571428571429, 0.825, 0.8339285714285715, 0.8357142857142857, 0.8285714285714286, 0.8357142857142857, 0.8285714285714286, 0.8375, 0.825, 0.8321428571428572, 0.8321428571428572, 0.8392857142857143, 0.8339285714285715, 0.8375, 0.8357142857142857, 0.8303571428571429, 0.8464285714285714, 0.8339285714285715, 0.8392857142857143, 0.8446428571428571, 0.8410714285714286, 0.8571428571428571, 0.8303571428571429, 0.8607142857142858, 0.8339285714285715, 0.8446428571428571, 0.8446428571428571, 0.8339285714285715, 0.8410714285714286, 0.8517857142857143, 0.8357142857142857, 0.8535714285714285, 0.8410714285714286, 0.8517857142857143, 0.85, 0.85, 0.8357142857142857, 0.8482142857142857, 0.8464285714285714, 0.8535714285714285, 0.8446428571428571, 0.8482142857142857, 0.8535714285714285, 0.85, 0.8535714285714285, 0.8571428571428571, 0.85, 0.8517857142857143, 0.8446428571428571, 0.85, 0.8446428571428571, 0.8357142857142857, 0.8517857142857143, 0.8553571428571428, 0.8267857142857142, 0.8589285714285714, 0.8517857142857143, 0.8357142857142857, 0.8428571428571429, 0.8607142857142858, 0.8571428571428571, 0.8428571428571429, 0.8625, 0.8589285714285714, 0.8571428571428571, 0.8339285714285715, 0.8625, 0.8517857142857143, 0.8642857142857143, 0.85, 0.8625, 0.8607142857142858, 0.8571428571428571, 0.8357142857142857, 0.85, 0.8589285714285714, 0.85, 0.8571428571428571]
Loss train:
[4.011032564299447, 1.8972771303994316, 1.2247104883193969, 0.9688620154346739, 0.84475593992642, 0.7633776771170753, 0.7232721086059298, 0.6641196898051671, 0.6211547911167145, 0.599787311894553, 0.5546612946050508, 0.5679011410900525, 0.554440872158323, 0.5444797979933875, 0.5392136309828077, 0.5173193850687572, 0.5001129254698753, 0.4876774719783238, 0.49186709352902, 0.4785576501062938, 0.468677439221314, 0.46603460418326514, 0.4488352903297969, 0.43167298776762825, 0.4405889700566019, 0.44579527186495915, 0.4301806324294635, 0.4342570021748543, 0.42601996958255767, 0.43043874991791586, 0.40396194798605783, 0.39719714841672354, 0.4038448521069118, 0.4037257916160992, 0.4030918395945004, 0.39704827815294264, 0.3780681303569249, 0.41156849073512214, 0.39239185197012766, 0.3758822873234749, 0.3797275430389813, 0.35906217311109817, 0.37786441019603184, 0.3727979293891362, 0.3800413978951318, 0.3644957071968487, 0.3546755015850067, 0.36832023837736677, 0.3709263720682689, 0.3381390741893223, 0.342908761543887, 0.37471544103963034, 0.3441260644367763, 0.3319265812635422, 0.35480674164635795, 0.3369794038789613, 0.33285661382334575, 0.3302720797913415, 0.3260045699775219, 0.3381365750517164, 0.32810446258102144, 0.35484942964145116, 0.32268465917025296, 0.32565766658101764, 0.32607218112264363, 0.3236482262611389, 0.33191952726670676, 0.30734745274697034, 0.31227819259677614, 0.3345008345586913, 0.3467956330095019, 0.318305787976299, 0.3019514228616442, 0.3173666319676808, 0.31164876094886235, 0.3202808380126953, 0.3050488643348217, 0.31457219038690837, 0.30796347579785754, 0.30954159285340993, 0.2945851304701396, 0.2926340131887368, 0.2777624615601131, 0.3004159892243998, 0.3060461370008332, 0.29674555893455234, 0.2977292307785579, 0.27623230761715345, 0.3007275026823793, 0.29786353441221375, 0.2820679145199912, 0.2858625811125551, 0.3051322493169989, 0.30274876419986996, 0.2919483085828168, 0.30022701269813945, 0.29950442569596425, 0.29070863191570556, 0.2876711352595261, 0.29191910411630356]
Test loss:
[2.7163328613553728, 1.4172410113470895, 1.0610152091298783, 0.8937725143773215, 0.7807373234203884, 0.7291359501225608, 0.6633276564734323, 0.6461966259138925, 0.591193254504885, 0.6026858525616782, 0.5686950990131923, 0.5732602460043771, 0.5493181024278914, 0.5357465369360788, 0.5179714288030351, 0.5502198926040105, 0.5440050414630345, 0.5083716877869198, 0.5094372970717294, 0.48752514975411554, 0.483368832724435, 0.4817440969603402, 0.4793070444038936, 0.49443304538726807, 0.49695766823632376, 0.45086956449917387, 0.46555825982775006, 0.4612330496311188, 0.47722708327429636, 0.44347339272499087, 0.4678123959473201, 0.45068034529685974, 0.4561645124639784, 0.4429003485611507, 0.44273159503936765, 0.4450558934892927, 0.4863553787980761, 0.4605599616255079, 0.42575898425919667, 0.43711539677211214, 0.43330001320157735, 0.4276367119380406, 0.45601119824818204, 0.416378573008946, 0.4351194032600948, 0.42368806515421187, 0.4339899914605277, 0.4260919460228511, 0.41418932165418354, 0.4495989424841745, 0.4171206942626408, 0.412625903742654, 0.44145078063011167, 0.42495072313717436, 0.4412474538598742, 0.42411878534725733, 0.41318929025105067, 0.42262059194701057, 0.43226068105016435, 0.407677287714822, 0.42250243510518753, 0.4021664023399353, 0.43413685049329487, 0.4166330754756927, 0.40209019609860014, 0.3972212893622262, 0.4149985151631492, 0.39663170661245073, 0.40871763484818596, 0.41164165139198305, 0.4189331122807094, 0.4283494617257799, 0.4258740041937147, 0.4249570071697235, 0.4284449790205274, 0.40573673844337466, 0.46682732360703605, 0.3910374011312212, 0.3986620937074934, 0.4356306195259094, 0.4264868353094373, 0.3864997020789555, 0.38596827558108737, 0.43021456599235536, 0.39449027265821185, 0.3875631323882512, 0.4049052442823138, 0.44653433561325073, 0.3920751988887787, 0.41607847043446133, 0.3863918440682547, 0.41421360543795993, 0.3908379307815007, 0.40130760840007235, 0.39873209084783284, 0.4256242300782885, 0.3975824304989406, 0.409307952438082, 0.43086038742746624, 0.3952910670212337]
Learning rate:
[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001]
Epoch times:
[29.38589334487915, 51.02310037612915, 70.00154900550842, 89.00890779495239, 107.72826838493347, 126.30855059623718, 145.2695438861847, 164.14990139007568, 182.86766648292542, 202.22443318367004, 220.84687733650208, 239.68839073181152, 258.71440386772156, 277.8530411720276, 296.5302953720093, 315.35954236984253, 334.2983832359314, 353.10147047042847, 372.1151294708252, 391.26002621650696, 409.9569661617279, 428.8986222743988, 447.95583057403564, 466.7014513015747, 485.414186000824, 504.2747347354889, 522.9953043460846, 541.7482280731201, 560.7337353229523, 579.4676959514618, 598.0123827457428, 617.1365482807159, 636.5009214878082, 655.4035618305206, 674.4370219707489, 693.1485214233398, 712.0435781478882, 731.2571244239807, 750.0139138698578, 768.7243809700012, 787.3004634380341, 806.2709422111511, 825.1053166389465, 843.6644546985626, 862.9031112194061, 881.7678878307343, 900.5978105068207, 919.4772431850433, 938.8790109157562, 957.9193794727325, 977.3296916484833, 996.7811436653137, 1016.0513632297516, 1035.0887570381165, 1054.5513544082642, 1073.7703957557678, 1093.3763287067413, 1112.997496843338, 1131.837991476059, 1150.8795988559723, 1170.1759564876556, 1189.236900806427, 1208.0770337581635, 1227.3801851272583, 1246.607885837555, 1266.5570640563965, 1286.3977863788605, 1305.2303647994995, 1324.0102574825287, 1343.4930293560028, 1362.1977579593658, 1381.4468786716461, 1400.7072281837463, 1419.5454769134521, 1438.6594908237457, 1458.4698631763458, 1477.9005992412567, 1497.403294801712, 1516.9542922973633, 1536.3527135849, 1555.4815683364868, 1575.5040273666382, 1594.7415251731873, 1613.4468922615051, 1632.747376203537, 1652.1706750392914, 1671.0182573795319, 1690.014161348343, 1709.3043117523193, 1728.378984451294, 1747.2053117752075, 1766.0804505348206, 1784.830489397049, 1803.693995475769, 1823.622707605362, 1843.2018830776215, 1861.9404909610748, 1881.2201447486877, 1899.8697521686554, 1918.961169242859]