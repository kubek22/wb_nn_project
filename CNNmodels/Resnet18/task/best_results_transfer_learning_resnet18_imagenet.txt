# final

learing_rate =  0.001
Training - Epoch 1/100, Loss: 1.2875, Accuracy: 53.5714%
Testing - Epoch 1/100, Loss: 0.8389, Accuracy: 77.1429%
Time: 24.94 seconds
learing_rate =  0.001
Training - Epoch 2/100, Loss: 0.7318, Accuracy: 78.4821%
Testing - Epoch 2/100, Loss: 0.6322, Accuracy: 79.8214%
Time: 46.18 seconds
learing_rate =  0.001
Training - Epoch 3/100, Loss: 0.5861, Accuracy: 81.8304%
Testing - Epoch 3/100, Loss: 0.5543, Accuracy: 81.9643%
Time: 65.09 seconds
learing_rate =  0.001
Training - Epoch 4/100, Loss: 0.5141, Accuracy: 83.5714%
Testing - Epoch 4/100, Loss: 0.4972, Accuracy: 82.5000%
Time: 83.97 seconds
learing_rate =  0.001
Training - Epoch 5/100, Loss: 0.4910, Accuracy: 83.9732%
Testing - Epoch 5/100, Loss: 0.4802, Accuracy: 83.7500%
Time: 103.52 seconds
learing_rate =  0.001
Training - Epoch 6/100, Loss: 0.4461, Accuracy: 84.9107%
Testing - Epoch 6/100, Loss: 0.4481, Accuracy: 85.0000%
Time: 122.58 seconds
learing_rate =  0.0005
Training - Epoch 7/100, Loss: 0.4079, Accuracy: 86.5625%
Testing - Epoch 7/100, Loss: 0.4563, Accuracy: 85.0000%
Time: 141.34 seconds
learing_rate =  0.0005
Training - Epoch 8/100, Loss: 0.3858, Accuracy: 87.8571%
Testing - Epoch 8/100, Loss: 0.4374, Accuracy: 83.9286%
Time: 160.85 seconds
learing_rate =  0.0005
Training - Epoch 9/100, Loss: 0.3823, Accuracy: 87.4107%
Testing - Epoch 9/100, Loss: 0.4367, Accuracy: 84.6429%
Time: 179.69 seconds
learing_rate =  0.0005
Training - Epoch 10/100, Loss: 0.3506, Accuracy: 88.9732%
Testing - Epoch 10/100, Loss: 0.4332, Accuracy: 85.8929%
Time: 198.76 seconds
learing_rate =  0.0005
Training - Epoch 11/100, Loss: 0.3454, Accuracy: 88.5268%
Testing - Epoch 11/100, Loss: 0.3933, Accuracy: 85.5357%
Time: 218.28 seconds
learing_rate =  0.0005
Training - Epoch 12/100, Loss: 0.3478, Accuracy: 88.4375%
Testing - Epoch 12/100, Loss: 0.3992, Accuracy: 85.7143%
Time: 237.44 seconds
learing_rate =  0.0005
Training - Epoch 13/100, Loss: 0.3324, Accuracy: 88.3929%
Testing - Epoch 13/100, Loss: 0.4262, Accuracy: 85.3571%
Time: 256.83 seconds
learing_rate =  0.0005
Training - Epoch 14/100, Loss: 0.3306, Accuracy: 88.5268%
Testing - Epoch 14/100, Loss: 0.4030, Accuracy: 86.2500%
Time: 275.95 seconds
learing_rate =  5e-05
Training - Epoch 15/100, Loss: 0.3057, Accuracy: 89.5536%
Testing - Epoch 15/100, Loss: 0.3821, Accuracy: 85.3571%
Time: 295.32 seconds
learing_rate =  5e-05
Training - Epoch 16/100, Loss: 0.3043, Accuracy: 89.2857%
Testing - Epoch 16/100, Loss: 0.3872, Accuracy: 87.3214%
Time: 314.57 seconds
learing_rate =  5e-05
Training - Epoch 17/100, Loss: 0.3072, Accuracy: 89.8214%
Testing - Epoch 17/100, Loss: 0.3854, Accuracy: 86.2500%
Time: 334.04 seconds
learing_rate =  5e-05
Training - Epoch 18/100, Loss: 0.2838, Accuracy: 90.7589%
Testing - Epoch 18/100, Loss: 0.3819, Accuracy: 85.8929%
Time: 353.73 seconds
learing_rate =  5e-05
Training - Epoch 19/100, Loss: 0.2837, Accuracy: 90.5357%
Testing - Epoch 19/100, Loss: 0.4085, Accuracy: 85.5357%
Time: 373.11 seconds
learing_rate =  5e-05
Training - Epoch 20/100, Loss: 0.2778, Accuracy: 90.3571%
Testing - Epoch 20/100, Loss: 0.3845, Accuracy: 85.1786%
Time: 392.46 seconds
learing_rate =  5e-05
Training - Epoch 21/100, Loss: 0.2710, Accuracy: 91.1161%
Testing - Epoch 21/100, Loss: 0.3712, Accuracy: 86.2500%
Time: 411.79 seconds
learing_rate =  5e-05
Training - Epoch 22/100, Loss: 0.2668, Accuracy: 90.8929%
Testing - Epoch 22/100, Loss: 0.3691, Accuracy: 87.3214%
Time: 430.58 seconds
learing_rate =  5e-05
Training - Epoch 23/100, Loss: 0.2794, Accuracy: 89.3750%
Testing - Epoch 23/100, Loss: 0.3794, Accuracy: 86.0714%
Time: 449.85 seconds
learing_rate =  5e-05
Training - Epoch 24/100, Loss: 0.2489, Accuracy: 91.3393%
Testing - Epoch 24/100, Loss: 0.3696, Accuracy: 86.7857%
Time: 469.41 seconds
learing_rate =  5e-05
Training - Epoch 25/100, Loss: 0.2494, Accuracy: 91.2054%
Testing - Epoch 25/100, Loss: 0.3597, Accuracy: 86.9643%
Time: 488.75 seconds
learing_rate =  5e-05
Training - Epoch 26/100, Loss: 0.2534, Accuracy: 90.8929%
Testing - Epoch 26/100, Loss: 0.3902, Accuracy: 86.7857%
Time: 508.73 seconds
learing_rate =  5e-05
Training - Epoch 27/100, Loss: 0.2403, Accuracy: 91.8304%
Testing - Epoch 27/100, Loss: 0.3867, Accuracy: 87.1429%
Time: 528.14 seconds
learing_rate =  5e-05
Training - Epoch 28/100, Loss: 0.2404, Accuracy: 91.5179%
Testing - Epoch 28/100, Loss: 0.3815, Accuracy: 85.7143%
Time: 547.28 seconds
learing_rate =  1e-06
Training - Epoch 29/100, Loss: 0.2289, Accuracy: 92.5446%
Testing - Epoch 29/100, Loss: 0.3750, Accuracy: 86.7857%
Time: 566.31 seconds
learing_rate =  1e-06
Training - Epoch 30/100, Loss: 0.2228, Accuracy: 92.6786%
Testing - Epoch 30/100, Loss: 0.3731, Accuracy: 87.6786%
Time: 585.83 seconds
learing_rate =  5e-05
Training - Epoch 31/100, Loss: 0.2401, Accuracy: 91.4286%
Testing - Epoch 31/100, Loss: 0.4106, Accuracy: 87.5000%
Time: 605.20 seconds
learing_rate =  1e-06
Training - Epoch 32/100, Loss: 0.2249, Accuracy: 92.3214%
Testing - Epoch 32/100, Loss: 0.3740, Accuracy: 86.7857%
Time: 624.40 seconds
learing_rate =  1e-06
Training - Epoch 33/100, Loss: 0.2154, Accuracy: 92.2321%
Testing - Epoch 33/100, Loss: 0.4073, Accuracy: 85.7143%
Time: 643.72 seconds
learing_rate =  1e-06
Training - Epoch 34/100, Loss: 0.2219, Accuracy: 92.5893%
Testing - Epoch 34/100, Loss: 0.3733, Accuracy: 87.1429%
Time: 663.06 seconds
learing_rate =  1e-06
Training - Epoch 35/100, Loss: 0.2143, Accuracy: 92.6786%
Testing - Epoch 35/100, Loss: 0.3663, Accuracy: 86.9643%
Time: 681.95 seconds
learing_rate =  1e-06
Training - Epoch 36/100, Loss: 0.2232, Accuracy: 92.0089%
Testing - Epoch 36/100, Loss: 0.3667, Accuracy: 87.3214%
Time: 701.46 seconds
learing_rate =  1e-06
Training - Epoch 37/100, Loss: 0.1952, Accuracy: 93.6161%
Testing - Epoch 37/100, Loss: 0.4065, Accuracy: 86.2500%
Time: 720.51 seconds
learing_rate =  1e-06
Training - Epoch 38/100, Loss: 0.2067, Accuracy: 92.8571%
Testing - Epoch 38/100, Loss: 0.3857, Accuracy: 86.4286%
Time: 739.41 seconds
learing_rate =  1e-06
Training - Epoch 39/100, Loss: 0.2096, Accuracy: 92.4554%
Testing - Epoch 39/100, Loss: 0.3906, Accuracy: 87.6786%
Time: 759.10 seconds
learing_rate =  1e-06
Training - Epoch 40/100, Loss: 0.1974, Accuracy: 93.2143%
Testing - Epoch 40/100, Loss: 0.3776, Accuracy: 87.6786%
Time: 778.32 seconds
learing_rate =  1e-06
Training - Epoch 41/100, Loss: 0.2002, Accuracy: 93.0357%
Testing - Epoch 41/100, Loss: 0.3673, Accuracy: 87.1429%
Time: 797.20 seconds
learing_rate =  1e-06
Training - Epoch 42/100, Loss: 0.2245, Accuracy: 92.0536%
Testing - Epoch 42/100, Loss: 0.3967, Accuracy: 86.6071%
Time: 816.51 seconds
learing_rate =  1e-06
Training - Epoch 43/100, Loss: 0.1956, Accuracy: 92.9464%
Testing - Epoch 43/100, Loss: 0.3952, Accuracy: 86.9643%
Time: 835.29 seconds
learing_rate =  1e-06
Training - Epoch 44/100, Loss: 0.2123, Accuracy: 92.6786%
Testing - Epoch 44/100, Loss: 0.3714, Accuracy: 87.3214%
Time: 854.16 seconds
learing_rate =  1e-06
Training - Epoch 45/100, Loss: 0.1906, Accuracy: 93.7054%
Testing - Epoch 45/100, Loss: 0.3868, Accuracy: 86.6071%
Time: 873.27 seconds
learing_rate =  1e-06
Training - Epoch 46/100, Loss: 0.2071, Accuracy: 92.4554%
Testing - Epoch 46/100, Loss: 0.3759, Accuracy: 87.5000%
Time: 892.60 seconds
learing_rate =  1e-06
Training - Epoch 47/100, Loss: 0.2016, Accuracy: 93.3929%
Testing - Epoch 47/100, Loss: 0.3703, Accuracy: 86.2500%
Time: 911.58 seconds
learing_rate =  1e-06
Training - Epoch 48/100, Loss: 0.1852, Accuracy: 93.5268%
Testing - Epoch 48/100, Loss: 0.4105, Accuracy: 86.6071%
Time: 930.65 seconds
learing_rate =  1e-06
Training - Epoch 49/100, Loss: 0.1862, Accuracy: 93.4821%
Testing - Epoch 49/100, Loss: 0.4197, Accuracy: 85.8929%
Time: 950.44 seconds
learing_rate =  1e-06
Training - Epoch 50/100, Loss: 0.1688, Accuracy: 94.1071%
Testing - Epoch 50/100, Loss: 0.3932, Accuracy: 87.1429%
Time: 969.51 seconds
learing_rate =  1e-06
Training - Epoch 51/100, Loss: 0.1682, Accuracy: 94.5536%
Testing - Epoch 51/100, Loss: 0.3726, Accuracy: 87.6786%
Time: 988.70 seconds
learing_rate =  1e-06
Training - Epoch 52/100, Loss: 0.1781, Accuracy: 93.8839%
Testing - Epoch 52/100, Loss: 0.3913, Accuracy: 86.6071%
Time: 1008.09 seconds
learing_rate =  1e-06
Training - Epoch 53/100, Loss: 0.1776, Accuracy: 94.1518%
Testing - Epoch 53/100, Loss: 0.3903, Accuracy: 86.9643%
Time: 1026.95 seconds
learing_rate =  1e-06
Training - Epoch 54/100, Loss: 0.1682, Accuracy: 94.8214%
Testing - Epoch 54/100, Loss: 0.4038, Accuracy: 86.2500%
Time: 1045.88 seconds
learing_rate =  1e-06
Training - Epoch 55/100, Loss: 0.1801, Accuracy: 94.1518%
Testing - Epoch 55/100, Loss: 0.3937, Accuracy: 88.0357%
Time: 1065.67 seconds
learing_rate =  1e-06
Training - Epoch 56/100, Loss: 0.1737, Accuracy: 94.6875%
Testing - Epoch 56/100, Loss: 0.3760, Accuracy: 88.2143%
Time: 1084.46 seconds
learing_rate =  1e-06
Training - Epoch 57/100, Loss: 0.1688, Accuracy: 94.6429%
Testing - Epoch 57/100, Loss: 0.3969, Accuracy: 86.4286%
Time: 1103.42 seconds
learing_rate =  1e-06
Training - Epoch 58/100, Loss: 0.1936, Accuracy: 93.0804%
Testing - Epoch 58/100, Loss: 0.4070, Accuracy: 87.5000%
Time: 1122.82 seconds
learing_rate =  1e-06
Training - Epoch 59/100, Loss: 0.1846, Accuracy: 93.7054%
Testing - Epoch 59/100, Loss: 0.3801, Accuracy: 88.2143%
Time: 1141.99 seconds
learing_rate =  1e-06
Training - Epoch 60/100, Loss: 0.1552, Accuracy: 95.1339%
Testing - Epoch 60/100, Loss: 0.3744, Accuracy: 87.5000%
Time: 1161.02 seconds
learing_rate =  1e-06
Training - Epoch 61/100, Loss: 0.1621, Accuracy: 93.7946%
Testing - Epoch 61/100, Loss: 0.3867, Accuracy: 87.8571%
Time: 1180.19 seconds
learing_rate =  1e-06
Training - Epoch 62/100, Loss: 0.1739, Accuracy: 93.4821%
Testing - Epoch 62/100, Loss: 0.3816, Accuracy: 85.8929%
Time: 1199.36 seconds
learing_rate =  1e-06
Training - Epoch 63/100, Loss: 0.1599, Accuracy: 94.9107%
Testing - Epoch 63/100, Loss: 0.4208, Accuracy: 86.9643%
Time: 1218.70 seconds
learing_rate =  1e-06
Training - Epoch 64/100, Loss: 0.1604, Accuracy: 94.6875%
Testing - Epoch 64/100, Loss: 0.3779, Accuracy: 87.6786%
Time: 1238.86 seconds
learing_rate =  1e-06
Training - Epoch 65/100, Loss: 0.1548, Accuracy: 94.8214%
Testing - Epoch 65/100, Loss: 0.3913, Accuracy: 86.9643%
Time: 1258.03 seconds
learing_rate =  1e-06
Training - Epoch 66/100, Loss: 0.1496, Accuracy: 95.0446%
Testing - Epoch 66/100, Loss: 0.4043, Accuracy: 86.9643%
Time: 1276.87 seconds
learing_rate =  1e-06
Training - Epoch 67/100, Loss: 0.1584, Accuracy: 94.9107%
Testing - Epoch 67/100, Loss: 0.3991, Accuracy: 87.1429%
Time: 1296.29 seconds
learing_rate =  1e-06
Training - Epoch 68/100, Loss: 0.1558, Accuracy: 94.9554%
Testing - Epoch 68/100, Loss: 0.4076, Accuracy: 86.7857%
Time: 1315.25 seconds
learing_rate =  1e-06
Training - Epoch 69/100, Loss: 0.1608, Accuracy: 94.8661%
Testing - Epoch 69/100, Loss: 0.4087, Accuracy: 87.1429%
Time: 1334.23 seconds
learing_rate =  1e-06
Training - Epoch 70/100, Loss: 0.1556, Accuracy: 94.5982%
Testing - Epoch 70/100, Loss: 0.3919, Accuracy: 87.5000%
Time: 1353.30 seconds
learing_rate =  1e-06
Training - Epoch 71/100, Loss: 0.1401, Accuracy: 95.3125%
Testing - Epoch 71/100, Loss: 0.4110, Accuracy: 86.7857%
Time: 1372.49 seconds
learing_rate =  1e-06
Training - Epoch 72/100, Loss: 0.1523, Accuracy: 94.7768%
Testing - Epoch 72/100, Loss: 0.3917, Accuracy: 87.1429%
Time: 1391.44 seconds
learing_rate =  1e-06
Training - Epoch 73/100, Loss: 0.1570, Accuracy: 94.0625%
Testing - Epoch 73/100, Loss: 0.4207, Accuracy: 86.7857%
Time: 1410.30 seconds
learing_rate =  1e-06
Training - Epoch 74/100, Loss: 0.1448, Accuracy: 95.0893%
Testing - Epoch 74/100, Loss: 0.4047, Accuracy: 86.6071%
Time: 1429.56 seconds
learing_rate =  1e-06
Training - Epoch 75/100, Loss: 0.1430, Accuracy: 94.8661%
Testing - Epoch 75/100, Loss: 0.4150, Accuracy: 86.7857%
Time: 1448.66 seconds
learing_rate =  1e-06
Training - Epoch 76/100, Loss: 0.1640, Accuracy: 94.4196%
Testing - Epoch 76/100, Loss: 0.4312, Accuracy: 85.7143%
Time: 1467.61 seconds
learing_rate =  1e-06
Training - Epoch 77/100, Loss: 0.1510, Accuracy: 95.2232%
Testing - Epoch 77/100, Loss: 0.3994, Accuracy: 86.7857%
Time: 1486.91 seconds
learing_rate =  1e-06
Training - Epoch 78/100, Loss: 0.1446, Accuracy: 95.0000%
Testing - Epoch 78/100, Loss: 0.4093, Accuracy: 86.6071%
Time: 1505.88 seconds
learing_rate =  1e-06
Training - Epoch 79/100, Loss: 0.1463, Accuracy: 94.6429%
Testing - Epoch 79/100, Loss: 0.4083, Accuracy: 87.3214%
Time: 1524.78 seconds
learing_rate =  1e-06
Training - Epoch 80/100, Loss: 0.1395, Accuracy: 95.7143%
Testing - Epoch 80/100, Loss: 0.4151, Accuracy: 87.1429%
Time: 1544.96 seconds
learing_rate =  1e-06
Training - Epoch 81/100, Loss: 0.1435, Accuracy: 95.2232%
Testing - Epoch 81/100, Loss: 0.4021, Accuracy: 86.4286%
Time: 1563.96 seconds
learing_rate =  1e-06
Training - Epoch 82/100, Loss: 0.1425, Accuracy: 95.4018%
Testing - Epoch 82/100, Loss: 0.4092, Accuracy: 86.4286%
Time: 1583.04 seconds
learing_rate =  1e-06
Training - Epoch 83/100, Loss: 0.1393, Accuracy: 95.0893%
Testing - Epoch 83/100, Loss: 0.4108, Accuracy: 87.5000%
Time: 1602.41 seconds
learing_rate =  1e-06
Training - Epoch 84/100, Loss: 0.1540, Accuracy: 94.7768%
Testing - Epoch 84/100, Loss: 0.4221, Accuracy: 86.2500%
Time: 1621.26 seconds
learing_rate =  1e-06
Training - Epoch 85/100, Loss: 0.1313, Accuracy: 95.4911%
Testing - Epoch 85/100, Loss: 0.4210, Accuracy: 87.5000%
Time: 1640.36 seconds
learing_rate =  1e-06
Training - Epoch 86/100, Loss: 0.1463, Accuracy: 94.3304%
Testing - Epoch 86/100, Loss: 0.4101, Accuracy: 86.6071%
Time: 1659.47 seconds
learing_rate =  1e-06
Training - Epoch 87/100, Loss: 0.1356, Accuracy: 94.9107%
Testing - Epoch 87/100, Loss: 0.4336, Accuracy: 87.1429%
Time: 1678.72 seconds
learing_rate =  1e-06
Training - Epoch 88/100, Loss: 0.1360, Accuracy: 96.0268%
Testing - Epoch 88/100, Loss: 0.4208, Accuracy: 87.8571%
Time: 1697.92 seconds
learing_rate =  1e-06
Training - Epoch 89/100, Loss: 0.1430, Accuracy: 95.0000%
Testing - Epoch 89/100, Loss: 0.4330, Accuracy: 86.6071%
Time: 1717.35 seconds
learing_rate =  1e-06
Training - Epoch 90/100, Loss: 0.1466, Accuracy: 94.8661%
Testing - Epoch 90/100, Loss: 0.4242, Accuracy: 87.6786%
Time: 1737.04 seconds
learing_rate =  1e-06
Training - Epoch 91/100, Loss: 0.1432, Accuracy: 95.0893%
Testing - Epoch 91/100, Loss: 0.4111, Accuracy: 86.7857%
Time: 1755.96 seconds
learing_rate =  1e-06
Training - Epoch 92/100, Loss: 0.1348, Accuracy: 95.7143%
Testing - Epoch 92/100, Loss: 0.4071, Accuracy: 87.1429%
Time: 1775.35 seconds
learing_rate =  1e-06
Training - Epoch 93/100, Loss: 0.1374, Accuracy: 95.3125%
Testing - Epoch 93/100, Loss: 0.4197, Accuracy: 87.6786%
Time: 1794.76 seconds
learing_rate =  1e-06
Training - Epoch 94/100, Loss: 0.1210, Accuracy: 96.0268%
Testing - Epoch 94/100, Loss: 0.4181, Accuracy: 86.7857%
Time: 1813.60 seconds
learing_rate =  1e-06
Training - Epoch 95/100, Loss: 0.1391, Accuracy: 95.0446%
Testing - Epoch 95/100, Loss: 0.4375, Accuracy: 86.4286%
Time: 1832.93 seconds
learing_rate =  1e-06
Training - Epoch 96/100, Loss: 0.1282, Accuracy: 95.4911%
Testing - Epoch 96/100, Loss: 0.4234, Accuracy: 86.2500%
Time: 1852.52 seconds
learing_rate =  1e-06
Training - Epoch 97/100, Loss: 0.1507, Accuracy: 94.1964%
Testing - Epoch 97/100, Loss: 0.4624, Accuracy: 85.7143%
Time: 1871.65 seconds
learing_rate =  1e-06
Training - Epoch 98/100, Loss: 0.1587, Accuracy: 94.7768%
Testing - Epoch 98/100, Loss: 0.4115, Accuracy: 87.8571%
Time: 1891.11 seconds
learing_rate =  1e-06
Training - Epoch 99/100, Loss: 0.1321, Accuracy: 95.4018%
Testing - Epoch 99/100, Loss: 0.4406, Accuracy: 86.2500%
Time: 1910.26 seconds
learing_rate =  1e-06
Training - Epoch 100/100, Loss: 0.1366, Accuracy: 95.0446%
Testing - Epoch 100/100, Loss: 0.4373, Accuracy: 86.7857%
Time: 1929.38 seconds
Training complete.
Training completed successfully.
Training accuracy:
[53.57142857142857, 78.48214285714286, 81.83035714285715, 83.57142857142857, 83.97321428571428, 84.91071428571428, 86.5625, 87.85714285714286, 87.41071428571429, 88.97321428571429, 88.52678571428572, 88.4375, 88.39285714285714, 88.52678571428572, 89.55357142857143, 89.28571428571429, 89.82142857142857, 90.75892857142858, 90.53571428571429, 90.35714285714286, 91.11607142857143, 90.89285714285714, 89.375, 91.33928571428571, 91.20535714285715, 90.89285714285714, 91.83035714285714, 91.51785714285714, 92.54464285714286, 92.67857142857143, 91.42857142857143, 92.32142857142858, 92.23214285714286, 92.58928571428572, 92.67857142857143, 92.00892857142857, 93.61607142857142, 92.85714285714286, 92.45535714285714, 93.21428571428572, 93.03571428571429, 92.05357142857142, 92.94642857142857, 92.67857142857143, 93.70535714285714, 92.45535714285714, 93.39285714285714, 93.52678571428571, 93.48214285714286, 94.10714285714286, 94.55357142857143, 93.88392857142858, 94.15178571428572, 94.82142857142857, 94.15178571428572, 94.6875, 94.64285714285714, 93.08035714285714, 93.70535714285714, 95.13392857142857, 93.79464285714286, 93.48214285714286, 94.91071428571428, 94.6875, 94.82142857142857, 95.04464285714286, 94.91071428571428, 94.95535714285714, 94.86607142857143, 94.59821428571429, 95.3125, 94.77678571428572, 94.0625, 95.08928571428571, 94.86607142857143, 94.41964285714286, 95.22321428571429, 95.0, 94.64285714285714, 95.71428571428572, 95.22321428571429, 95.40178571428571, 95.08928571428571, 94.77678571428572, 95.49107142857143, 94.33035714285715, 94.91071428571428, 96.02678571428571, 95.0, 94.86607142857143, 95.08928571428571, 95.71428571428572, 95.3125, 96.02678571428571, 95.04464285714286, 95.49107142857143, 94.19642857142857, 94.77678571428572, 95.40178571428571, 95.04464285714286]
Test accuracy:
[77.14285714285715, 79.82142857142858, 81.96428571428571, 82.5, 83.75, 85.0, 85.0, 83.92857142857143, 84.64285714285714, 85.89285714285714, 85.53571428571428, 85.71428571428571, 85.35714285714285, 86.25, 85.35714285714285, 87.32142857142857, 86.25, 85.89285714285714, 85.53571428571428, 85.17857142857143, 86.25, 87.32142857142857, 86.07142857142858, 86.78571428571429, 86.96428571428572, 86.78571428571429, 87.14285714285714, 85.71428571428571, 86.78571428571429, 87.67857142857143, 87.5, 86.78571428571429, 85.71428571428571, 87.14285714285714, 86.96428571428572, 87.32142857142857, 86.25, 86.42857142857143, 87.67857142857143, 87.67857142857143, 87.14285714285714, 86.60714285714286, 86.96428571428572, 87.32142857142857, 86.60714285714286, 87.5, 86.25, 86.60714285714286, 85.89285714285714, 87.14285714285714, 87.67857142857143, 86.60714285714286, 86.96428571428572, 86.25, 88.03571428571428, 88.21428571428571, 86.42857142857143, 87.5, 88.21428571428571, 87.5, 87.85714285714286, 85.89285714285714, 86.96428571428572, 87.67857142857143, 86.96428571428572, 86.96428571428572, 87.14285714285714, 86.78571428571429, 87.14285714285714, 87.5, 86.78571428571429, 87.14285714285714, 86.78571428571429, 86.60714285714286, 86.78571428571429, 85.71428571428571, 86.78571428571429, 86.60714285714286, 87.32142857142857, 87.14285714285714, 86.42857142857143, 86.42857142857143, 87.5, 86.25, 87.5, 86.60714285714286, 87.14285714285714, 87.85714285714286, 86.60714285714286, 87.67857142857143, 86.78571428571429, 87.14285714285714, 87.67857142857143, 86.78571428571429, 86.42857142857143, 86.25, 85.71428571428571, 87.85714285714286, 86.25, 86.78571428571429]
Loss train:
[1.287484007222312, 0.7318366519042424, 0.5860984244516918, 0.514121567777225, 0.49100095459393095, 0.44607578963041306, 0.40793614621673313, 0.38576409710305076, 0.3823499413473265, 0.35059218896286826, 0.3453617532338415, 0.34779987846102034, 0.33239436617919377, 0.3306440230991159, 0.3056919398052352, 0.3042594097554684, 0.3072024398616382, 0.28384869088019643, 0.2836738616228104, 0.2777570733002254, 0.2710468256047794, 0.2667860312121255, 0.27935574278235437, 0.24891781200255667, 0.24943878299423627, 0.2534427237297807, 0.2403123239321368, 0.24042135168399129, 0.22893917933106422, 0.22282316477171013, 0.24007867393749102, 0.22493692934513093, 0.21536013010357108, 0.22191328534058163, 0.2143040472375495, 0.22321888080665042, 0.19521556943655013, 0.2066797855177096, 0.2096439101334129, 0.19739548532026155, 0.20018557459115982, 0.22445751705339978, 0.19559149625045913, 0.21233340267624173, 0.19060046396085195, 0.20705053423132216, 0.20161713542682783, 0.18517930417188577, 0.18623013155800955, 0.16875024203743252, 0.16815841884485314, 0.17807447516492436, 0.17758222350052424, 0.16816791466304234, 0.18007400397743498, 0.17367498049778599, 0.1688493794628552, 0.19355755815548556, 0.18460115114493028, 0.15524944085627795, 0.16205337281738008, 0.17389104046991893, 0.15992655365594796, 0.16035451548440116, 0.15482369980641775, 0.14964854062667915, 0.15844565284039294, 0.15582991516483682, 0.16081859235252652, 0.1556428184998887, 0.1400759286646332, 0.1522650527634791, 0.15701650444950377, 0.14479007832705976, 0.14303089984293496, 0.16403885462454387, 0.15104938947728702, 0.14458304159343244, 0.14628448092511723, 0.13951764165290764, 0.1435348049338375, 0.14250495604106359, 0.13926464090389865, 0.1539994499246989, 0.13133712562599353, 0.1462529272905418, 0.13562201524951628, 0.1359861885862691, 0.14303870733295168, 0.1465614148016487, 0.14316353936280524, 0.1347640575574977, 0.13742997872510127, 0.12101086984787668, 0.13907199933060577, 0.1282279545707362, 0.15067516935190983, 0.15872222456548896, 0.13211933393031358, 0.1365971568173596]
Test loss:
[0.8388757722718375, 0.6322453081607818, 0.5542962482997349, 0.49718623076166424, 0.4801685401371547, 0.44807338884898595, 0.45634634239333016, 0.4373535326548985, 0.4366874498980386, 0.4332016374383654, 0.39326767240251814, 0.3991562383515494, 0.42624599082129344, 0.40300399661064146, 0.38210871304784505, 0.3871648933206286, 0.38539302008492604, 0.3819097306047167, 0.4085285748754229, 0.38452579975128176, 0.37115761467388697, 0.3691376507282257, 0.37941879885537283, 0.3696360102721623, 0.3597383754593985, 0.3901608850274767, 0.38667237077440536, 0.3814918126378741, 0.37502271022115435, 0.37314854179109846, 0.4105600144181933, 0.3740399752344404, 0.4072576914514814, 0.37331720335142954, 0.36631326590265545, 0.3666932787214007, 0.4065188901765006, 0.38567331433296204, 0.39055449536868503, 0.37762001412255425, 0.3673375632081713, 0.39669992072241644, 0.39519363982336864, 0.3713759158338819, 0.3868222841194698, 0.3759462484291622, 0.3703400841781071, 0.4105026406901223, 0.4196566241128104, 0.3932006061077118, 0.37262403454099385, 0.39125136988503595, 0.39033998250961305, 0.40377021091324944, 0.39368743896484376, 0.37601631283760073, 0.3969074879373823, 0.4069818879876818, 0.3800682170050485, 0.37436001215662273, 0.3867107936314174, 0.3816303185054234, 0.42075455699648173, 0.3779185090746198, 0.3913040322916848, 0.40426267215183803, 0.39907962509563993, 0.4076308957168034, 0.40869713340486796, 0.3918667784758976, 0.41096208095550535, 0.3916992153440203, 0.4207197640623365, 0.4047055797917502, 0.41496032902172636, 0.43123098526682174, 0.39938457693372453, 0.40931820443698336, 0.40832227638789587, 0.4150680822985513, 0.40212317194257463, 0.40922052689961025, 0.4107565641403198, 0.4220610499382019, 0.42098416260310584, 0.4101213080542428, 0.43356857129505705, 0.4208383483546121, 0.4330081973757063, 0.424176721061979, 0.4111030467918941, 0.4070695834500449, 0.41967169897896905, 0.41810840112822395, 0.43753148913383483, 0.42339374933923996, 0.4624076707022531, 0.4114928986345019, 0.4405714503356389, 0.437255506004606]
Learning rate:
[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05, 1e-06, 1e-06, 5e-05, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06]
Epoch times:
[24.93934988975525, 46.184988021850586, 65.09458613395691, 83.9725432395935, 103.52129697799683, 122.57709956169128, 141.34096455574036, 160.85341382026672, 179.68637490272522, 198.75513434410095, 218.2753529548645, 237.4380431175232, 256.8338134288788, 275.95216274261475, 295.31844544410706, 314.5717840194702, 334.0437138080597, 353.7317819595337, 373.10996317863464, 392.46469020843506, 411.7889997959137, 430.57879853248596, 449.8521304130554, 469.41326332092285, 488.75253438949585, 508.7303669452667, 528.1400411128998, 547.2753002643585, 566.31134557724, 585.8258152008057, 605.1995825767517, 624.3960056304932, 643.7243750095367, 663.0614538192749, 681.9530625343323, 701.4608373641968, 720.5102877616882, 739.4146699905396, 759.0986359119415, 778.3230395317078, 797.1971576213837, 816.5139491558075, 835.2895061969757, 854.1621351242065, 873.2718033790588, 892.6041035652161, 911.5754687786102, 930.6486160755157, 950.4394245147705, 969.5147383213043, 988.6960413455963, 1008.0870680809021, 1026.9534537792206, 1045.8812379837036, 1065.6749420166016, 1084.4606354236603, 1103.4215314388275, 1122.8238260746002, 1141.9874305725098, 1161.0216944217682, 1180.1920447349548, 1199.3625066280365, 1218.7027904987335, 1238.8620109558105, 1258.0276846885681, 1276.8677451610565, 1296.286729335785, 1315.245491027832, 1334.231324672699, 1353.2959475517273, 1372.4890167713165, 1391.4444370269775, 1410.2994871139526, 1429.5636467933655, 1448.662972688675, 1467.6149756908417, 1486.9131078720093, 1505.881117105484, 1524.7814366817474, 1544.9555830955505, 1563.9592781066895, 1583.0421869754791, 1602.4123375415802, 1621.258736371994, 1640.3561363220215, 1659.4744741916656, 1678.7163503170013, 1697.9213571548462, 1717.3508701324463, 1737.0363173484802, 1755.9557871818542, 1775.3546953201294, 1794.7628064155579, 1813.5981795787811, 1832.9291071891785, 1852.5208480358124, 1871.654048204422, 1891.1140291690826, 1910.259385585785, 1929.384174823761]